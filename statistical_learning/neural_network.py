# -*- coding: utf-8 -*-
"""Homework 5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GnS8YMARy0G-J1kzmM1cDAwvKWkLGB7y
"""

import numpy as np
import matplotlib.pyplot as plt
import scipy as sp
import pandas as pd
import tensorflow
from tensorflow.keras.datasets import cifar10
from tensorflow.keras import models
from tensorflow.keras import layers

"""# **LOADING CIFAR 10 DATA:**

The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.

(**NOTE: ONLY THE DESCRIPTION WAS TAKEN TO LEARN MORE ABOUT THE DATA SET: https://www.cs.toronto.edu/~kriz/cifar.html**)
"""

#%%
(X_train,Y_train), (X_test, Y_test) = cifar10.load_data()

"""**Visualizing the Data**"""

#%%
numTrainExamples = X_train.shape[0]
# Visualize a randomly selected training example:
plt.figure
i = np.random.randint(numTrainExamples)
plt.imshow(X_train[i,:,:],cmap=plt.get_cmap('gray'))

"""**Assignment Details:**

Rules: Don't touch the test data. Design your convolutional neural network using only the training data. You can do whatever you want with the training data, but I recommend breaking it up into a reduced training set and a validation set. Another option to consider is using cross-validation when tuning hyperparameters in your CNN.

Once you submit your code, I'll test your model on the test data and see what accuracy you get.
"""

#One Hot Encoding
Y_train = tensorflow.keras.utils.to_categorical(Y_train)
Y_test = tensorflow.keras.utils.to_categorical(Y_test)

X_train = X_train.reshape((50000,32,32,3))
X_train = X_train.astype('float64')



#%%
numVal = 10000
X_val = X_train[0:numVal,:]
Y_val = Y_train[0:numVal:]

X_train_partial = X_train[numVal:,:]
Y_train_partial = Y_train[numVal:]

"""**Creating the CNN**"""

network = models.Sequential()
network.add(layers.Conv2D(64,(3,3), activation = 'relu', input_shape = (32,32,3)))
network.add(layers.Conv2D(64,(3,3), activation = 'relu'))
network.add(layers.MaxPooling2D((2,2)))
network.add(layers.Conv2D(64,(3,3), activation = 'relu'))
network.add(layers.Dense(64, activation = 'relu'))
network.add(layers.MaxPooling2D((2,2)))
network.add(layers.MaxPooling2D((2,2)))
network.add(layers.Conv2D(64,(2,2), activation = 'relu'))
network.add(layers.Conv2D(64,(1,1), activation = 'relu'))
network.add(layers.Dense(64, activation = 'relu'))
network.add(layers.MaxPooling2D((1,1)))

network.add(layers.Flatten())
network.add(layers.Dense(64, activation = 'relu'))
network.add(layers.Dense(10, activation = 'softmax'))

network.compile(optimizer = 'Adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])

#%%
#I am thinking if I did a few more epochs it would do better...but it takes a long time. LOL.
history = network.fit(X_train_partial, Y_train_partial, epochs = 6,batch_size =10, validation_data = (X_val, Y_val))

#%%
history_dict = history.history
loss_values = history_dict['loss']
val_loss_values = history_dict['val_loss']
history_dict['val_loss']

epochs = range(1, len(loss_values) + 1)

plt.plot(epochs, loss_values, 'bo',label = 'Training loss')
plt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

#%%
plt.clf()
acc_values = history_dict['acc']
val_acc_values = history_dict['val_acc']

plt.plot(epochs, acc_values,'bo',label = 'Training acc')
plt.plot(epochs, val_acc_values,'b', label = 'Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()


#How well did I do?
#test_loss, test_acc = network.evaluate(X_test,Y_test)